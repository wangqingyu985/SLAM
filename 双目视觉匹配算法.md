kinect等基于ToF的相机获取室内点云效果是很好的，但是在室外光照变化的条件下效果不好，因此需要用双目立体视觉匹配的方法。

结构光相机可以覆盖从显微微观到宏观的所有层面，而ToF相机只能覆盖宏观层面。

#### 基于双目立体视觉的深度相机（被动深度相机）

不对外主动投射光源，案例：ZED、BumbleBee

#### 基于ToF的深度相机

Kinect v2

#### 基于结构光原理的深度相机

Kinect v1、realsense



## SGBM算法：

### 一、预处理

水平sobel算子

映射函数

![2b3bf0abd86e2125bdca5c050b8a45ea.png](https://www.freesion.com/images/474/2b3bf0abd86e2125bdca5c050b8a45ea.png)

### 二、代价计算

1.预处理的图像基于采样的方法得到梯度代价

2.原图像基于采样的方法得到SAD代价

然后将两者相加

SAD： Sum of Absolute Difference

![](https://img-blog.csdn.net/20160709143416235?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

![img](https://www.freesion.com/images/45/e086b969f8820a96cb74974220e8452d.png)

### 三、动态规划



![e29fc7329a421e05e3636f875ef7a0be.png](https://www.freesion.com/images/982/e29fc7329a421e05e3636f875ef7a0be.png)

![5fccedbb331a6f5e8e2bee8cbb05bd6f.png](https://www.freesion.com/images/335/5fccedbb331a6f5e8e2bee8cbb05bd6f.png)

![df8c266d7f4e71716cb163ad644df6b1.png](https://www.freesion.com/images/473/df8c266d7f4e71716cb163ad644df6b1.png)

### 四、后处理

1.唯一性检测：对每个像素计算最小代价和次最小代价的值，若两者相对差小于一定阈值，则被剔除。

2.亚像素插值：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200320100610433.PNG#pic_center)

3.左右一致性检测（LRC chech，Left-Right Consistency Check）：若以左图为参考对象，p点在右图的匹配点为pd；则以右图为参考对象时，点pd在左图的对应匹配点应为点p。若不满足这一约束条件的点则认为是遮挡点或误匹配。



主要参数是 SADWindowSize、numberOfDisparities和uniquenessRatio三个，一般只需对这三个参数进行调整，其余参数按默认设置即可



## 立体匹配一般包含的四个步骤：

匹配代价计算（matching cost computation）：AD、SAD、NCC、MI（互信息）、CT、RT、BT、AD-Census等。

代价聚合（cost aggregation）：扫面线法、动态规划法、SGM中的路径聚合法等。

视差计算（disparity computation）：WTA。

视差提炼（disparity refinement）：左右一致性检测、亚像素插值、双边滤波、中值滤波。

## AD-Census包含的四个步骤：

初始代价计算：AD+Census

代价聚合：基于十字交叉域代价聚合

扫描线优化：（类似于SGM中的代价聚合）

视差优化：离群点检测、迭代局部投票、适当插值、视差非连续区域调整、子像素优化

## 立体匹配技术难点：

光照变化、强光反射、透视畸变、弱纹理、重复纹理、遮挡

## 北京邮电大学硕士论文基于深度学习算法的双目立体视觉匹配：

全卷积网络结构采用双塔式网络结构，去掉全连接层，输入为同一场景对应的两张的图像，输出为视差图。